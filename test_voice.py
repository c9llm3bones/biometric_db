# test_speechbrain.py

import torchaudio
from speechbrain.pretrained import EncoderClassifier
import numpy as np
import os
import torch

def extract_speaker_embedding(audio_path):
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç 192-–º–µ—Ä–Ω—ã–π –≤–µ–∫—Ç–æ—Ä –≥–æ–ª–æ—Å–∞ —Å –ø–æ–º–æ—â—å—é SpeechBrain
    :param audio_path: –ø—É—Ç—å –∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª—É
    :return: –≤–µ–∫—Ç–æ—Ä (list) –∏–ª–∏ None
    """
    try:
        # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ (–≤ –ø–µ—Ä–≤—ã–π —Ä–∞–∑ —Å–∫–∞—á–∞–µ—Ç ~300 –ú–ë)
        spk_model = EncoderClassifier.from_hparams(
            source="speechbrain/spkrec-ecapa-voxceleb"
        )

        # –ó–∞–≥—Ä—É–∑–∫–∞ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞
        if not os.path.exists(audio_path):
            print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {audio_path}")
            return None

        signal, fs = torchaudio.load(audio_path)
        if signal.shape[0] > 1:
            signal = signal[0].unsqueeze(0)  # –º–æ–Ω–æ
        print(f"‚úÖ –ê—É–¥–∏–æ—Ñ–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω (—á–∞—Å—Ç–æ—Ç–∞: {fs} –ì—Ü)")

        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–∞
        with torch.no_grad():
            embedding = spk_model.encode_batch(signal).squeeze().tolist()
        print(f"‚úÖ –í–µ–∫—Ç–æ—Ä –∏–∑–≤–ª–µ—á–µ–Ω: {len(embedding)} –∏–∑–º–µ—Ä–µ–Ω–∏–π")
        return embedding

    except Exception as e:
        print("‚ùå –û—à–∏–±–∫–∞:", e)
        return None

if __name__ == "__main__":
    # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    audio_path = "/home/kostya/biometric_course_work/dataset/voices/Registration/Kostya.ogg"
    #vector = extract_speaker_embedding(audio_path)

    #if vector:
    #    print("\nüìä –ü–µ—Ä–≤—ã–µ 10 –∫–æ–º–ø–æ–Ω–µ–Ω—Ç –≤–µ–∫—Ç–æ—Ä–∞:")
    #    print(vector[:10])
    
    # test_comparison.py
    import numpy as np
    from utils.voice_utils import extract_speechbrain_vector, normalize_vector

    # –í–µ–∫—Ç–æ—Ä –∏–∑ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏
    vec1 = extract_speechbrain_vector("/home/kostya/biometric_course_work/dataset/voices/Registration/Kostya.ogg")
    vec1 = normalize_vector(vec1)

    # –í–µ–∫—Ç–æ—Ä –∏–∑ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏
    vec2 = extract_speechbrain_vector("/home/kostya/biometric_course_work/dataset/voices/Authorization/Ira_1.ogg")
    vec2 = normalize_vector(vec2)

    # L2-—Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ
    l2_distance = np.linalg.norm(np.array(vec1) - np.array(vec2))
    print("L2-—Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ:", l2_distance)

    # –ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ
    cos_sim = np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))
    print("–ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ:", cos_sim)